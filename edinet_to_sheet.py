#!/usr/bin/env python3
# ---------------------------------------------------------------------------
#  edinet_to_sheet.py   2025-06  v1.0
# ---------------------------------------------------------------------------
#  âœ“ æŒ‡å®šæ—¥ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šJST å½“æ—¥ï¼‰ã® EDINET æœ‰å ±ï¼å››åŠå ±ã‚’å–å¾—
#  âœ“ ZIP-XBRL ã‚’è§£æã—ä¸»è¦æ•°å€¤ã‚’æŠ½å‡º
#  âœ“ æœŸæƒ…å ±ã‹ã‚‰åˆ†é¡åˆ— (FY2025Q1 ãªã©) ã‚’ç”Ÿæˆ
#  âœ“ Google Sheets ã¸ä¸€æ‹¬è»¢è¨˜ï¼ˆDRY_RUN=1 ã§ CSV ã®ã¿å‡ºåŠ›ï¼‰
# ---------------------------------------------------------------------------
import os, sys, io, zipfile, re, json, datetime
from typing import Optional, List

import requests, pandas as pd
from dateutil import tz
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# â”€â”€ å¿…é ˆç’°å¢ƒå¤‰æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EDINET_KEY  = os.getenv("EDINET_KEY")  or sys.exit("âŒ EDINET_KEY æœªè¨­å®š")
GSHEET_JSON = os.getenv("GSHEET_JSON") or sys.exit("âŒ GSHEET_JSON æœªè¨­å®š")

# â”€â”€ ä»»æ„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TARGET_DATE  = os.getenv("TARGET_DATE")             # 'YYYY-MM-DD'
MAX_DOCS     = int(os.getenv("MAX_DOCS", "50"))     # 0=åˆ¶é™ãªã—
DRY_RUN      = os.getenv("DRY_RUN") == "1"

SPREADSHEET  = os.getenv("SPREADSHEET_NAME", "EDINET_MONITOR")
SHEET_NAME   = os.getenv("SHEET_NAME",      "EDINET_FILINGS")

# â”€â”€ å®šæ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_URL = "https://api.edinet-fsa.go.jp/api/v2"
JST      = tz.gettz("Asia/Tokyo")

TAGS = {
    "Revenue":        ["jpcrp_cor:NetSales", "ifrs-full:Revenue"],
    "OperatingIncome":["jpcrp_cor:OperatingIncome", "ifrs-full:OperatingProfit"],
    "OrdinaryIncome": ["jpcrp_cor:OrdinaryIncome"],
    "ProfitParent":   ["jpcrp_cor:ProfitAttributableToOwnersOfParent",
                       "ifrs-full:ProfitLoss"],
    "EPS":            ["jpcrp_cor:EarningsPerShare",
                       "ifrs-full:BasicEarningsLossPerShare"],
}

# â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def grab(xbrl: str, tag_list: List[str]) -> Optional[float]:
    for tag in tag_list:
        m = re.search(fr"<{tag}[^>]*>([\d\.\-]+)</{tag}>", xbrl)
        if m:
            return float(m.group(1))
    return None

def fetch_xbrl_record(meta: dict) -> dict:
    doc_id = meta["docID"]
    r = requests.get(
        f"{BASE_URL}/documents/{doc_id}",
        params={"type": 5},
        headers={"Ocp-Apim-Subscription-Key": EDINET_KEY},
        timeout=30
    )
    r.raise_for_status()
    with zipfile.ZipFile(io.BytesIO(r.content)) as z:
        xbrl_name = next(n for n in z.namelist() if n.endswith(".xbrl"))
        xbrl = z.read(xbrl_name).decode("utf-8", "ignore")

    rec = {
        "docID":        doc_id,
        "secCode":      meta.get("secCode",""),
        "submitDate":   meta.get("submitDateTime","")[:10],
        "fiscalYear":   meta.get("fiscalYear"),
        "fiscalPeriod": meta.get("fiscalPeriod"),
    }
    rec["classification"] = (
        f"FY{rec['fiscalYear']}{rec['fiscalPeriod']}" if rec["fiscalYear"] and rec["fiscalPeriod"] else ""
    )

    for col,tags in TAGS.items():
        rec[col] = grab(xbrl, tags)
    return rec

def get_target() -> str:
    if TARGET_DATE:
        return TARGET_DATE
    return datetime.datetime.now(JST).strftime("%Y-%m-%d")

# â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    target = get_target()
    print(f"â–¶ï¸ TARGET_DATE={target}  MAX_DOCS={MAX_DOCS or 'âˆ'}  DRY_RUN={DRY_RUN}")

    docs = requests.get(
        f"{BASE_URL}/documents.json",
        params={"date": target, "type": 2},
        headers={"Ocp-Apim-Subscription-Key": EDINET_KEY},
        timeout=30
    ).json().get("results", [])
    xbrl_docs = [d for d in docs if d.get("xbrlFlag")=="1"]
    if MAX_DOCS: xbrl_docs = xbrl_docs[:MAX_DOCS]

    print(f"  docs={len(docs)}, xbrl={len(xbrl_docs)}")

    records = []
    for d in xbrl_docs:
        try:
            records.append(fetch_xbrl_record(d))
        except Exception as e:
            print(f"âš ï¸ {d['docID']} skip: {e}")

    df = pd.DataFrame(records)
    print(f"RESULT rows={len(df)}")

    if DRY_RUN or df.empty:
        if not df.empty:
            df.to_csv("edinet_test.csv", index=False, encoding="utf-8-sig")
            print("ğŸ’¾ CSV å‡ºåŠ› â†’ edinet_test.csv")
        return

    creds = ServiceAccountCredentials.from_json_keyfile_dict(
        json.loads(GSHEET_JSON),
        ["https://www.googleapis.com/auth/spreadsheets",
         "https://www.googleapis.com/auth/drive"]
    )
    gc = gspread.authorize(creds)
    ss = gc.open(SPREADSHEET)
    try:
        ws = ss.worksheet(SHEET_NAME); ws.clear()
    except gspread.WorksheetNotFound:
        ws = ss.add_worksheet(title=SHEET_NAME, rows=str(len(df)+5), cols=str(len(df.columns)))

    ws.update([df.columns.tolist()] + df.astype(str).values.tolist(),
              value_input_option="USER_ENTERED")
    print(f"âœ… Wrote {len(df)} rows â†’ {SPREADSHEET}/{SHEET_NAME}")

if __name__ == "__main__":
    main()
