#!/usr/bin/env python3
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ultra_light_edinet.py
#  ---------------------------------------------------------------
#  ãƒ»æ¤œè¨¼ç”¨ã®æœ€å°æ§‹æˆ:
#      - å¯¾è±¡æ—¥ä»˜ã¯ 1 æ—¥ã ã‘ï¼ˆéå»æ—¥ã‚’æ¨å¥¨ï¼‰
#      - XBRL ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚å…ˆé ­ N ä»¶ã ã‘
#      - Google Sheets æ›¸ãè¾¼ã¿ã¯è¡Œæ•°ãŒ 0 ã®å ´åˆã‚¹ã‚­ãƒƒãƒ—
#  ãƒ»ç’°å¢ƒå¤‰æ•°ï¼ˆSecrets ãŒä¾¿åˆ©ï¼‰
#      EDINET_KEY   : EDINET API ã‚­ãƒ¼           (å¿…é ˆ)
#      GSHEET_JSON  : Google SA JSON           (å¿…é ˆ)
#      TEST_DATE    : å–å¾—æ—¥ (YYYY-MM-DD)      (çœç•¥æ™‚ 2024-05-01)
#      MAX_DOCS     : 1 æ—¥ã‚ãŸã‚Šå–å¾—ä¸Šé™ N     (çœç•¥æ™‚ 3)
#      SKIP_SHEET   : "1" ã§ Sheets ã¸æ›¸ã‹ãªã„ (ä»»æ„)
# ----------------------------------------------------------------

import os, datetime, io, zipfile, re, json, sys
from typing import Optional

import requests, pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from dateutil import tz

# â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EDINET_KEY  = os.getenv("EDINET_KEY")  or sys.exit("âŒ EDINET_KEY æœªè¨­å®š")
GSHEET_JSON = os.getenv("GSHEET_JSON") or sys.exit("âŒ GSHEET_JSON æœªè¨­å®š")

TEST_DATE = os.getenv("TEST_DATE", "2024-05-01")           # å®Ÿãƒ‡ãƒ¼ã‚¿ã®ã‚ã‚‹æ—¥ã‚’æ¨å¥¨
MAX_DOCS  = int(os.getenv("MAX_DOCS", "3"))                # å–å¾—ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šé™
SKIP_SHEET = os.getenv("SKIP_SHEET") == "1"                # æ›¸è¾¼ã¿ã‚¹ã‚­ãƒƒãƒ—?

SPREADSHEET = os.getenv("SPREADSHEET_NAME", "EDINET_MONITOR")
SHEET_NAME  = os.getenv("SHEET_NAME", "EDINET_FILINGS")

BASE_URL = "https://api.edinet-fsa.go.jp/api/v2"
JST = tz.gettz("Asia/Tokyo")

TAGS = {
    "Revenue":        ["jpcrp_cor:NetSales","ifrs-full:Revenue"],
    "OperatingIncome":["jpcrp_cor:OperatingIncome","ifrs-full:OperatingProfit"],
    "OrdinaryIncome": ["jpcrp_cor:OrdinaryIncome"],
    "ProfitParent":   ["jpcrp_cor:ProfitAttributableToOwnersOfParent","ifrs-full:ProfitLoss"],
    "EPS":            ["jpcrp_cor:EarningsPerShare","ifrs-full:BasicEarningsLossPerShare"],
}

# â”€â”€ é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def grab_value(xbrl: str, tags: list[str]) -> Optional[float]:
    for tag in tags:
        m = re.search(fr"<{tag}[^>]*>([\d\.\-]+)</{tag}>", xbrl)
        if m:
            return float(m.group(1))
    return None

def fetch_xbrl_data(doc: dict) -> dict:
    z = requests.get(
        f"{BASE_URL}/documents/{doc['docID']}",
        params={"type":5,"Subscription-Key":EDINET_KEY}, timeout=30
    ).content
    with zipfile.ZipFile(io.BytesIO(z)) as zp:
        inst = next(n for n in zp.namelist() if n.endswith(".xbrl"))
        xbrl = zp.read(inst).decode("utf-8","ignore")

    rec = {
        "docID":        doc["docID"],
        "secCode":      doc.get("secCode",""),
        "submitDate":   doc.get("submitDateTime","")[:10],
        "fiscalYear":   doc.get("fiscalYear"),
        "fiscalPeriod": doc.get("fiscalPeriod"),
        "classification": f"FY{doc.get('fiscalYear')}{doc.get('fiscalPeriod')}",
    }
    for col,taglist in TAGS.items():
        rec[col] = grab_value(xbrl, taglist)
    return rec

# â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print(f"â–¶ï¸ TEST_DATE = {TEST_DATE}, MAX_DOCS = {MAX_DOCS}")
    params = {"date": TEST_DATE, "type": 2, "Subscription-Key": EDINET_KEY}
    docs = requests.get(f"{BASE_URL}/documents.json", params=params, timeout=30).json().get("results", [])
    xbrl_docs = [d for d in docs if d.get("xbrlFlag") == "1"][:MAX_DOCS]

    print(f"  Found {len(docs)} docs, XBRL sliced to {len(xbrl_docs)}")

    recs = []
    for d in xbrl_docs:
        try:
            recs.append(fetch_xbrl_data(d))
        except Exception as e:
            print(f"âš ï¸ {d['docID']} skip: {e}")

    df = pd.DataFrame(recs)
    print(f"RESULT â†’ rows = {len(df)}")
    if df.empty or SKIP_SHEET:
        print("ğŸ›ˆ DataFrame ãŒç©ºã€ã¾ãŸã¯æ›¸è¾¼ã¿ã‚¹ã‚­ãƒƒãƒ—æŒ‡å®šã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # Sheets æ›¸è¾¼ã¿
    creds = ServiceAccountCredentials.from_json_keyfile_dict(
        json.loads(GSHEET_JSON),
        ["https://www.googleapis.com/auth/spreadsheets","https://www.googleapis.com/auth/drive"]
    )
    gc = gspread.authorize(creds)
    sh = gc.open(SPREADSHEET)
    try:
        ws = sh.worksheet(SHEET_NAME); ws.clear()
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title=SHEET_NAME, rows=str(len(df)+1), cols=str(len(df.columns)))
    ws.update([df.columns.tolist()] + df.astype(str).values.tolist(), value_input_option="USER_ENTERED")
    print(f"âœ… Wrote {len(df)} rows to '{SHEET_NAME}' in '{SPREADSHEET}'.")

if __name__ == "__main__":
    main()
